{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1780004,"sourceType":"datasetVersion","datasetId":1058286}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2  # For image processing\nimport gc\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator  # For image augmentation\nfrom tensorflow.keras.models import Sequential  # For building the neural network\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout  # For defining CNN layers\nfrom tensorflow.keras.optimizers import Adam  # For the optimizer\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix  # For evaluation","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-21T08:12:23.280077Z","iopub.execute_input":"2024-08-21T08:12:23.281179Z","iopub.status.idle":"2024-08-21T08:12:37.571580Z","shell.execute_reply.started":"2024-08-21T08:12:23.281135Z","shell.execute_reply":"2024-08-21T08:12:37.570578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_path = '/kaggle/input/gender-dataset/Dataset/Train/Female/000001.jpg'\n\n# Load the image using OpenCV\nimage = cv2.imread(image_path)\n\n# Convert the image from BGR (OpenCV default) to RGB (Matplotlib default)\nimage_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n# Plot the image using Matplotlib\nplt.imshow(image_rgb)\nplt.axis('off')  # Turn off axis labels\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-21T08:12:37.573394Z","iopub.execute_input":"2024-08-21T08:12:37.574549Z","iopub.status.idle":"2024-08-21T08:12:37.829683Z","shell.execute_reply.started":"2024-08-21T08:12:37.574508Z","shell.execute_reply":"2024-08-21T08:12:37.828800Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dir = '/kaggle/input/gender-dataset/Dataset/Train'\nval_dir = '/kaggle/input/gender-dataset/Dataset/Validation'\n\ndef get_data(directory):\n    data = []\n    for gender in ['Male', 'Female']:\n        gender_dir = os.path.join(directory, gender)\n        for img_name in os.listdir(gender_dir):\n            img_path = os.path.join(gender_dir, img_name)\n            label = 0 if gender == 'Male' else 1\n            data.append((img_path, label))\n    return data\n\n# Combine train and validation data\ntrain_data = get_data(train_dir)\nval_data = get_data(val_dir)\ndata = train_data + val_data\n\n# Create DataFrame\ndf = pd.DataFrame(data, columns=['image_path', 'label'])\n\n# Shuffle the DataFrame\ndf = df.sample(frac=1, random_state=42).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-21T08:12:37.830973Z","iopub.execute_input":"2024-08-21T08:12:37.831334Z","iopub.status.idle":"2024-08-21T08:12:46.938905Z","shell.execute_reply.started":"2024-08-21T08:12:37.831294Z","shell.execute_reply":"2024-08-21T08:12:46.938103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd\n\ntrain_dir = '/kaggle/input/gender-dataset/Dataset/Train'\nval_dir = '/kaggle/input/gender-dataset/Dataset/Validation'\n\ndef get_data(directory):\n    data = []\n    for gender in ['Male', 'Female']:\n        gender_dir = os.path.join(directory, gender)\n        for img_name in os.listdir(gender_dir):\n            img_path = os.path.join(gender_dir, img_name)\n            # Map gender to numerical label\n            label = 0 if gender == 'Male' else 1\n            data.append((img_path, label))\n    return data\n\n# Combine datasets\ntrain_data = get_data(train_dir)\nval_data = get_data(val_dir)\ndata = train_data + val_data\n\n# Delete intermediate variables\ndel train_data, val_data\ngc.collect()\n\n# Create DataFrame\ndf = pd.DataFrame(data, columns=['image_path', 'label'])\n\n# Delete the data list\ndel data\ngc.collect()\n\n# Separate male and female samples\nmale_samples = df[df['label'] == 0]\nfemale_samples = df[df['label'] == 1]\n\n# Determine the number of samples to keep (40% of the smaller class)\nn_samples = int(min(len(male_samples), len(female_samples)) * 0.4)\n\n# Randomly sample an equal number of male and female images\nmale_samples = male_samples.sample(n=n_samples, random_state=42)\nfemale_samples = female_samples.sample(n=n_samples, random_state=42)\n\n# Combine the sampled data\ndf_balanced = pd.concat([male_samples, female_samples])\n\n# Delete intermediate DataFrames\ndel male_samples, female_samples\ngc.collect()\n\n# Shuffle the final dataset\ndf_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n\n# Delete the original DataFrame\ndel df\ngc.collect()\n\n# Display first few rows and basic info\nprint(df_balanced.head())\nprint(\"\\nDataset shape:\", df_balanced.shape)\nprint(\"\\nClass distribution:\")\nprint(df_balanced['label'].value_counts(normalize=True))","metadata":{"execution":{"iopub.status.busy":"2024-08-21T08:12:46.941276Z","iopub.execute_input":"2024-08-21T08:12:46.941932Z","iopub.status.idle":"2024-08-21T08:12:48.384475Z","shell.execute_reply.started":"2024-08-21T08:12:46.941896Z","shell.execute_reply":"2024-08-21T08:12:48.383499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df_balanced[:30])","metadata":{"execution":{"iopub.status.busy":"2024-08-21T08:12:48.385518Z","iopub.execute_input":"2024-08-21T08:12:48.385801Z","iopub.status.idle":"2024-08-21T08:12:48.392602Z","shell.execute_reply.started":"2024-08-21T08:12:48.385776Z","shell.execute_reply":"2024-08-21T08:12:48.391732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_height, img_width = 64, 64  # Adjust as needed\n\n# Function to load images and labels\ndef load_images_and_labels(df):\n    X = []\n    y = []\n    total_images = len(df)\n    \n    for i, (_, row) in enumerate(df.iterrows()):\n        img = load_img(row['image_path'], target_size=(img_height, img_width))\n        img_array = img_to_array(img) / 255.0  # Normalize the image to [0, 1]\n        X.append(img_array)\n        y.append(row['label'])\n        \n        # Print progress every 1000 images\n        if (i + 1) % 1000 == 0:\n            print(f\"Processed {i + 1}/{total_images} images\")\n    \n    print(f\"Finished processing all {total_images} images\")\n    return np.array(X), np.array(y)","metadata":{"execution":{"iopub.status.busy":"2024-08-21T08:12:48.393919Z","iopub.execute_input":"2024-08-21T08:12:48.394328Z","iopub.status.idle":"2024-08-21T08:12:48.403806Z","shell.execute_reply.started":"2024-08-21T08:12:48.394296Z","shell.execute_reply":"2024-08-21T08:12:48.402987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df, test_df = train_test_split(df_balanced, test_size=0.2, random_state=42, stratify=df_balanced['label'])\n\n# Delete the balanced DataFrame\ndel df_balanced\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-08-21T08:12:48.405002Z","iopub.execute_input":"2024-08-21T08:12:48.405439Z","iopub.status.idle":"2024-08-21T08:12:48.643015Z","shell.execute_reply.started":"2024-08-21T08:12:48.405406Z","shell.execute_reply":"2024-08-21T08:12:48.642099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, y_train = load_images_and_labels(train_df)\nX_test, y_test = load_images_and_labels(test_df)\n\n# Garbage collect the split DataFrames\ndel train_df, test_df\ngc.collect()\n\n# Display shapes of the loaded data\nprint(\"X_train shape:\", X_train.shape)\nprint(\"y_train shape:\", y_train.shape)\nprint(\"X_test shape:\", X_test.shape)\nprint(\"y_test shape:\", y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2024-08-21T08:12:48.644251Z","iopub.execute_input":"2024-08-21T08:12:48.644615Z","iopub.status.idle":"2024-08-21T08:22:02.201095Z","shell.execute_reply.started":"2024-08-21T08:12:48.644581Z","shell.execute_reply":"2024-08-21T08:22:02.200218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_train[0])","metadata":{"execution":{"iopub.status.busy":"2024-08-21T08:22:11.662495Z","iopub.execute_input":"2024-08-21T08:22:11.663158Z","iopub.status.idle":"2024-08-21T08:22:11.669360Z","shell.execute_reply.started":"2024-08-21T08:22:11.663124Z","shell.execute_reply":"2024-08-21T08:22:11.668410Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import models, layers\n\ninput_shape = (64, 64, 3)  # Input size of 64x64\nn_classes = 1\n\nmodel = models.Sequential([\n    layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n    layers.BatchNormalization(),\n    layers.MaxPooling2D((2, 2)),\n\n    layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n    layers.BatchNormalization(),\n    layers.MaxPooling2D((2, 2)),\n\n    layers.Conv2D(128, kernel_size=(3, 3), activation='relu'),\n    layers.BatchNormalization(),\n    layers.MaxPooling2D((2, 2)),\n\n    layers.Conv2D(128, kernel_size=(3, 3), activation='relu'),\n    layers.BatchNormalization(),\n    layers.MaxPooling2D((2, 2)),\n\n    layers.Flatten(),\n    layers.Dense(64, activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dense(n_classes, activation='sigmoid'),\n])\n\n# Summary of the model\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-21T08:27:17.178372Z","iopub.execute_input":"2024-08-21T08:27:17.179051Z","iopub.status.idle":"2024-08-21T08:27:17.305743Z","shell.execute_reply.started":"2024-08-21T08:27:17.179017Z","shell.execute_reply":"2024-08-21T08:27:17.304878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(\n    optimizer='adam',\n    loss='binary_crossentropy',\n    metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-21T08:27:20.234058Z","iopub.execute_input":"2024-08-21T08:27:20.234440Z","iopub.status.idle":"2024-08-21T08:27:20.243723Z","shell.execute_reply.started":"2024-08-21T08:27:20.234408Z","shell.execute_reply":"2024-08-21T08:27:20.242764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-08-21T08:27:20.563146Z","iopub.execute_input":"2024-08-21T08:27:20.563557Z","iopub.status.idle":"2024-08-21T08:27:20.594189Z","shell.execute_reply.started":"2024-08-21T08:27:20.563526Z","shell.execute_reply":"2024-08-21T08:27:20.593303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 8\nepochs = 20\n\nhistory = model.fit(\n    X_train, y_train,                # Training data and labels\n    validation_data=(X_test, y_test), # Validation data and labels\n    batch_size=batch_size,            # Batch size\n    epochs=epochs,                    # Number of epochs\n    verbose=1                         # Print progress during training\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-21T08:27:20.845907Z","iopub.execute_input":"2024-08-21T08:27:20.846932Z","iopub.status.idle":"2024-08-21T08:34:44.687671Z","shell.execute_reply.started":"2024-08-21T08:27:20.846893Z","shell.execute_reply":"2024-08-21T08:34:44.686630Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing import image\n\ntarget_size = (64, 64)\npath_testmodel = \"/kaggle/input/gender-dataset/Dataset/Test/Female/160029.jpg\"\nimge = image.load_img(path_testmodel, target_size=target_size)\nX = image.img_to_array(imge)\nX = np.expand_dims(X, axis=0)\n\nimages = np.vstack([X])\nclasses = model.predict(images, batch_size=1)\nprint(classes[0])\nif classes[0]<0.5:\n    print(\"This is a male\")\nelse:\n    print( \"This  is a female\")\nplt.imshow(imge)","metadata":{"execution":{"iopub.status.busy":"2024-08-21T08:41:22.819878Z","iopub.execute_input":"2024-08-21T08:41:22.821023Z","iopub.status.idle":"2024-08-21T08:41:23.150762Z","shell.execute_reply.started":"2024-08-21T08:41:22.820977Z","shell.execute_reply":"2024-08-21T08:41:23.149801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}